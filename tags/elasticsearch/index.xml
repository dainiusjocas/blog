<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elasticsearch | Dainius Jocas</title><link>https://www.jocas.lt/blog/tags/elasticsearch/</link><atom:link href="https://www.jocas.lt/blog/tags/elasticsearch/index.xml" rel="self" type="application/rss+xml"/><description>Elasticsearch</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2021 Dainius Jocas</copyright><lastBuildDate>Wed, 12 May 2021 18:00:00 +0000</lastBuildDate><image><url>img/map[gravatar:%!s(bool=false) shape:circle]</url><title>Elasticsearch</title><link>https://www.jocas.lt/blog/tags/elasticsearch/</link></image><item><title>Don't Change the Partition Count for Kafka Topics!</title><link>https://www.jocas.lt/blog/talk/wearedevelopers-2021-05-12/</link><pubDate>Wed, 12 May 2021 18:00:00 +0000</pubDate><guid>https://www.jocas.lt/blog/talk/wearedevelopers-2021-05-12/</guid><description>&lt;iframe src="//www.slideshare.net/slideshow/embed_code/key/kZMqDKr91XpXnv" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> &lt;/iframe> &lt;div style="margin-bottom:5px"> &lt;strong> &lt;a href="//www.slideshare.net/Dainius/dont-change-the-partition-count-for-kafka-topics-248323982" title="Don&amp;#x27;t change the partition count for kafka topics!" target="_blank">Don&amp;#x27;t change the partition count for kafka topics!&lt;/a> &lt;/strong> from &lt;strong>&lt;a href="//www.slideshare.net/Dainius" target="_blank">Dainius Jocas&lt;/a>&lt;/strong> &lt;/div></description></item><item><title>Don't Change the Partition Count for Kafka Topics!</title><link>https://www.jocas.lt/blog/talk/vilnius-cloud-native-2021-04-07/</link><pubDate>Wed, 07 Apr 2021 19:00:00 +0000</pubDate><guid>https://www.jocas.lt/blog/talk/vilnius-cloud-native-2021-04-07/</guid><description>&lt;iframe src="//www.slideshare.net/slideshow/embed_code/key/A50Ec2sJ1SRG32" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> &lt;/iframe> &lt;div style="margin-bottom:5px"> &lt;strong> &lt;a href="//www.slideshare.net/Dainius/dont-change-the-partition-count-for-kafka-topics" title="Don&amp;#x27;t change the partition count for kafka topics!" target="_blank">Don&amp;#x27;t change the partition count for kafka topics!&lt;/a> &lt;/strong> from &lt;strong>&lt;a href="https://www.slideshare.net/Dainius" target="_blank">Dainius Jocas&lt;/a>&lt;/strong> &lt;/div></description></item><item><title>How to Prevent Data Corruption in Elasticsearch When Using Kafka Connect Elasticsearch Sink Connector</title><link>https://www.jocas.lt/blog/post/kc_es_data_consistency/</link><pubDate>Sat, 03 Oct 2020 00:00:00 +0000</pubDate><guid>https://www.jocas.lt/blog/post/kc_es_data_consistency/</guid><description>&lt;h3 id="tldr">TL;DR&lt;/h3>
&lt;p>When the &lt;a href="https://github.com/confluentinc/kafka-connect-elasticsearch">Elasticsearch indexer&lt;/a> is highly concurrent, Kafka record keys are used as Elasticsearch document IDs, and indexer is set to delete records on &lt;code>null&lt;/code> values, then Kafka Connect Elasticsearch Sink Connector might corrupt your data: documents that should not be deleted end up being deleted, or documents that should be deleted end up still being present in the index. The fix is to use external versioning for deletes in bulk requests as it is proposed in this &lt;a href="https://github.com/confluentinc/kafka-connect-elasticsearch/pull/422">Github Pull Request&lt;/a>.&lt;/p>
&lt;h3 id="the-problem">The problem&lt;/h3>
&lt;p>NOTE: as of version 6.0.0 of the Confluent Platform (last checked on 2020-10-02) the bug that might lead to data corruption is still present.&lt;/p>
&lt;p>Let&amp;rsquo;s focus on a use case where Kafka record key is used as an Elasticsearch document ID&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. I would consider this to be a proper practice when the documents represent a catalog of things.&lt;/p>
&lt;p>Elasticsearch uses &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/optimistic-concurrency-control.html">optimistic concurrency control&lt;/a>. The job of this concurrency mechanism is to ensure that older version of the document doesn&amp;rsquo;t override a newer version. By default, order of arrival of the operation is applied, but the behaviour can be overriden in &lt;a href="https://www.elastic.co/blog/elasticsearch-versioning-support">several ways&lt;/a> depending on the version of Elasticsearch. In this post we focus on concurrent bulk requests, and with a concurrency that involves a network, requests will sometimes arrive out of order.&lt;/p>
&lt;p>To help Elasticsearch resolve the out-of-order indexing requests Kafka Connect Elasticsearch Sink Connector (from here on Kafka Connect for short) leverages the &lt;a href="https://github.com/confluentinc/kafka-connect-elasticsearch/blob/7256e9473cea690c373058b88fffd1111870cfe6/src/main/java/io/confluent/connect/elasticsearch/jest/JestElasticsearchClient.java#L564">&lt;code>external&lt;/code> document&lt;/a> versioning&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. Using external versions in Kafka Connect makes sense because we already have versioning in place: Kafka topic partition offsets. If Kafka Connect applies changes to Elasticsearch indices in order of the topic offset, then any update ordering problems would be problems in the upstream system. This is a good guarantee to have.&lt;/p>
&lt;p>Let&amp;rsquo;s add to the mix delete operations. Kafka Connect supports a setting &lt;code>BEHAVIOR_ON_NULL_VALUES_CONFIG&lt;/code> to &lt;code>&amp;quot;delete&amp;quot;&lt;/code>. This setting instructs the Kafka Connect that a document in Elasticsearch with an ID of the kafka record key with &lt;code>null&lt;/code> value (a tombstone message) is going to be deleted. But for some strange reason the deletes &lt;strong>does not use external versioning&lt;/strong>! The line responsible for the described behaviour&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> can be found &lt;a href="https://github.com/confluentinc/kafka-connect-elasticsearch/blob/7256e9473cea690c373058b88fffd1111870cfe6/src/main/java/io/confluent/connect/elasticsearch/jest/JestElasticsearchClient.java#L554">here&lt;/a>. This means that for deletes the order-of-arrival wins. Let&amp;rsquo;s increase the concurrency of bulk requests with the param &lt;code>MAX_IN_FLIGHT_REQUESTS_CONFIG&lt;/code> to a largish number, and the data consistency problems is just round the corner for data that has some largish update ratio.&lt;/p>
&lt;p>The issue is even more pronounced when you re-index data into Elasticsearch and you want to do it as fast as possible, which means doing the indexing concurrently.&lt;/p>
&lt;h3 id="the-example">The Example&lt;/h3>
&lt;p>The code that demonstrated the faulty behaviour can be found in this &lt;a href="https://github.com/confluentinc/kafka-connect-elasticsearch/pull/422">Pull Request&lt;/a>.&lt;/p>
&lt;p>The test case is for testing the case when document should be present in Elasticsearch gets deleted.&lt;/p>
&lt;p>Let&amp;rsquo;s have a little walk over the code snippet:&lt;/p>
&lt;pre>&lt;code class="language-java">Collection&amp;lt;SinkRecord&amp;gt; records = new ArrayList&amp;lt;&amp;gt;();
for (int i = 0; i &amp;lt; numOfRecords - 1 ; i++) {
if (i % 2 == 0) {
SinkRecord sinkRecord = new SinkRecord(TOPIC, PARTITION, Schema.STRING_SCHEMA, key, schema, null, i);
records.add(sinkRecord);
} else {
record.put(&amp;quot;message&amp;quot;, Integer.toString(i));
SinkRecord sinkRecord = new SinkRecord(TOPIC, PARTITION, Schema.STRING_SCHEMA, key, schema, record, i);
records.add(sinkRecord);
}
}
record.put(&amp;quot;message&amp;quot;, Integer.toString(numOfRecords));
SinkRecord sinkRecord = new SinkRecord(TOPIC, PARTITION, Schema.STRING_SCHEMA, key, schema, record, numOfRecords);
records.add(sinkRecord);
task.put(records);
task.flush(null);
&lt;/code>&lt;/pre>
&lt;p>Here we send &lt;code>numOfRecords&lt;/code> (which larger than 2) to a Kafka topic. Every second record has &lt;code>null&lt;/code> body (delete operation), and the rest of the records have a sequence number as a &lt;code>message&lt;/code> value. The very last record is &lt;strong>always&lt;/strong> a non-null record with a &lt;code>message&lt;/code> value of &lt;code>numOfRecords&lt;/code>.&lt;/p>
&lt;p>Let&amp;rsquo;s setup a connector:&lt;/p>
&lt;pre>&lt;code class="language-java">KEY_IGNORE_CONFIG = &amp;quot;false&amp;quot;;
MAX_IN_FLIGHT_REQUESTS_CONFIG = Integer.toString(numOfRecords)
BATCH_SIZE_CONFIG = &amp;quot;1&amp;quot;
LINGER_MS_CONFIG = &amp;quot;1&amp;quot;
BEHAVIOR_ON_NULL_VALUES_CONFIG = &amp;quot;delete&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Here we set a connector to use Kafka record key as id &lt;code>KEY_IGNORE_CONFIG = &amp;quot;false&amp;quot;&lt;/code>, set the indexer concurrency to the &lt;code>numOfRecords&lt;/code>; set the indexing batch size to 1 (this creates as many requests to Elasticsearch as there are records in the Kafka topic); set indexer to send requests immediately with &lt;code>LINGER_MS_CONFIG = &amp;quot;1&amp;quot;&lt;/code>; and record with a &lt;code>null&lt;/code> value represents a delete operation.&lt;/p>
&lt;p>With this setup after the indexing is done we expect that in the index we have a document with ID and whose &lt;code>message&lt;/code> value is &lt;code>numOfRecords&lt;/code>. But when ordering of bulk requests is out-of-order then at the end we might have a situation where there is no document in the index at all: the bulk index request with &lt;code>message = numOfRecords&lt;/code> arrived before one of the bulk requests with a delete operation!&lt;/p>
&lt;p>The situation might seem to be a bit far-fetched but for applications like e-commerce where you have a catalog that is frequently updated (e.g. the catalog item should be available in search or not) and updates are modelled as document deletes it happens a bit more often than it might be expected.&lt;/p>
&lt;h3 id="the-fix">The fix&lt;/h3>
&lt;p>The fix is simple: use the same external versioning that is already being used by the indexing requests also for delete requests:&lt;/p>
&lt;pre>&lt;code class="language-java">if (record.version != null) {
req.setParameter(&amp;quot;version_type&amp;quot;, &amp;quot;external&amp;quot;).setParameter(&amp;quot;version&amp;quot;, record.version);
}
&lt;/code>&lt;/pre>
&lt;p>The full code can be found &lt;a href="ttps://github.com/confluentinc/kafka-connect-elasticsearch/pull/422">here&lt;/a>. Let&amp;rsquo;s hope that Confluent developers will find some time to merge that PR.&lt;/p>
&lt;h3 id="conclusion">Conclusion&lt;/h3>
&lt;p>Thank you for reading and leave your feedback &lt;a href="https://github.com/dainiusjocas/blog/issues/12">here&lt;/a>.&lt;/p>
&lt;h3 id="ps">P.S.&lt;/h3>
&lt;p>Of course, this is not the only situation when data can get &lt;a href="https://github.com/confluentinc/kafka-connect-elasticsearch/issues">corrupted&lt;/a>, e.g. changing the number of partitions; when you delete the topic, repopulate it with up-to-date data (also, you skip deletes) then restarting the indexing might pretty much nothing, because all the versions are earlier &lt;code>external version&lt;/code> because offsets are smaller.&lt;/p>
&lt;h3 id="heading">&lt;/h3>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>When Kafka Record keys are not used as Elasticsearch document IDs versioning is not a problem because every Elasticsearch ID is constructed as &lt;code>{topic}+{partition}+{offset}&lt;/code> which creates a new document for every Kafka record, i.e. no versioning is needed. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Elasticsearch 7 supports the &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/breaking-changes-7.0.html#_internal_versioning_is_no_longer_supported_for_optimistic_concurrency_control">external versioning&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Yes, it is a comment, and it means that the developers were not sure whether to use external versioning for delete operations. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>How to Use Elasticsearch Ingest Pipelines with Kafka Connect Elasticsearch Sink Connector</title><link>https://www.jocas.lt/blog/post/ingest_pipeline_kafka_connect/</link><pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate><guid>https://www.jocas.lt/blog/post/ingest_pipeline_kafka_connect/</guid><description>&lt;h3 id="tldr">TL;DR&lt;/h3>
&lt;p>Specify your pipeline with the &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html#dynamic-index-settings">&lt;code>index.default_pipeline&lt;/code>&lt;/a> setting in the index (or index template) settings.&lt;/p>
&lt;h3 id="the-problem">The Problem&lt;/h3>
&lt;p>We need to index the log data into the &lt;a href="https://www.elastic.co/">Elasticsearch&lt;/a> cluster using a &lt;a href="https://docs.confluent.io/current/connect/kafka-connect-elasticsearch/index.html">Kafka Connect Elasticsearch Sink Connector&lt;/a> &lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, the data should be split into daily indices, and we need to specify the Elasticsearch ingest pipeline.&lt;/p>
&lt;p>The &lt;a href="https://docs.confluent.io/current/connect/kafka-connect-elasticsearch/configuration_options.html">documentation of the connector&lt;/a> doesn&amp;rsquo;t mention anything about ingest pipelines. After a quick consultation with the Internet you discover that there is an open &lt;a href="https://github.com/confluentinc/kafka-connect-elasticsearch/issues/72">issue&lt;/a> that Kafka Connect Elasticsearch Sink Connector doesn&amp;rsquo;t support specifying an Elasticsearch ingest pipeline. WAT?&lt;/p>
&lt;h3 id="the-workaround">The Workaround&lt;/h3>
&lt;p>Say&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>, our pipeline&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> just renames an attribute, e.g.:&lt;/p>
&lt;pre>&lt;code class="language-shell">PUT _ingest/pipeline/my_pipeline_id
{
&amp;quot;description&amp;quot; : &amp;quot;renames the field name&amp;quot;,
&amp;quot;processors&amp;quot; : [
{
&amp;quot;rename&amp;quot;: {
&amp;quot;field&amp;quot;: &amp;quot;original_field_name&amp;quot;,
&amp;quot;target_field&amp;quot;: &amp;quot;target_field_name&amp;quot;
}
}
]
}
&lt;/code>&lt;/pre>
&lt;p>The Elasticsearch ingest pipeline for indexing can be specified in several ways:&lt;/p>
&lt;ol>
&lt;li>for each index request as a &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/ingest.html">URL parameter&lt;/a>,&lt;/li>
&lt;li>per bulk index request as a URL parameter,&lt;/li>
&lt;li>for every &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html#docs-bulk-api-query-params">bulk index request operation&lt;/a>,&lt;/li>
&lt;li>index settings (&lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html#dynamic-index-settings">a dynamic attribute&lt;/a>),&lt;/li>
&lt;li>index template.&lt;/li>
&lt;/ol>
&lt;p>First three options are not supported by Kafka Connect. The fourth option is not convenient in our case because the data should be split into time-based (e.g. daily) indices and we don&amp;rsquo;t want to do repetitive tasks&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>. The natural option to follow is to define an &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-templates.html">index template&lt;/a>. In the index template we can specify the &lt;code>index.default_pipeline&lt;/code> parameter, e.g.&lt;/p>
&lt;pre>&lt;code class="language-shell">PUT _index_template/template_1
{
&amp;quot;index_patterns&amp;quot;: [&amp;quot;daily_log*&amp;quot;],
&amp;quot;template&amp;quot;: {
&amp;quot;settings&amp;quot;: {
&amp;quot;index.default_pipeline&amp;quot;: &amp;quot;my_pipeline_id&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Note, that for indexing not to fail, we should create the Elasticsearch ingest pipeline&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup> &lt;strong>before&lt;/strong> setting up the index template.&lt;/p>
&lt;p>That is it, now when Kafka Connect will create a new daily index the Elasticsearch ingest pipeline is going to be applied to every document without any issues, for free, and in no time.&lt;/p>
&lt;h3 id="bonus">Bonus&lt;/h3>
&lt;p>One thing to note is that only one pipeline can be specified for &lt;code>index.default_pipeline&lt;/code> which might sound a bit limiting. A clever trick to overcome that limitation is to use a series of &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/pipeline-processor.html">pipeline processors&lt;/a> that can invoke other pipelines in the specified order, i.e. pipeline of pipelines.&lt;/p>
&lt;p>Also, there is an index setting called &lt;code>index.final_pipeline&lt;/code> that if specified is going to be executed after all other pipelines.&lt;/p>
&lt;p>Testing pipelines can be done using the &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/simulate-pipeline-api.html">&lt;code>_simulate&lt;/code> API&lt;/a>.&lt;/p>
&lt;h3 id="fin">Fin&lt;/h3>
&lt;p>Thanks for reading and leave comments or any other feedback on this blog post in the &lt;a href="https://github.com/dainiusjocas/blog/issues/9">Github issue&lt;/a>. Examples were tested to work with Elasticsearch and Kibana 7.8.1.&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>or any other technology that doesn&amp;rsquo;t support, or it is just not possible to specify the Elasticsearch ingest pipeline. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>yes, I know that the same job can be done with the &lt;a href="https://docs.confluent.io/current/connect/transforms/index.html">Kafka Connect Transformations&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>let&amp;rsquo;s leave out the Kafka Connector setup. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>set &lt;code>index.default_pipeline=my_pipeline_id&lt;/code> for every new daily index with, say, a cron-job at midnight. &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>technically, before an index is created that matches the template pattern. &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>A Neat Trick with Elasticsearch Normalizers</title><link>https://www.jocas.lt/blog/post/elasticsearch-normlizers/</link><pubDate>Wed, 08 Jul 2020 00:00:00 +0000</pubDate><guid>https://www.jocas.lt/blog/post/elasticsearch-normlizers/</guid><description>&lt;p>To analyze the textual data Elasticsearch uses &lt;strong>analyzers&lt;/strong> while for the keyword analysis there is a thing called a &lt;strong>normalizer&lt;/strong>. In this article I&amp;rsquo;ll explain what the normalizer is and show it&amp;rsquo;s use case for &lt;strong>normalizing&lt;/strong> URLs.&lt;/p>
&lt;h2 id="tldr">TL;DR&lt;/h2>
&lt;p>A neat use case for keyword normalizers is to extract a specific part of the URL with a char_filter of the &lt;code>pattern_replace&lt;/code> type.&lt;/p>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>In Elasticsearch the textual data is represented with two data types: &lt;code>text&lt;/code> and &lt;code>keyword&lt;/code>. The &lt;code>text&lt;/code> type is meant to be used for full-text search use cases while &lt;code>keyword&lt;/code> is mean for filtering, sorting, and aggregation.&lt;/p>
&lt;h3 id="tldr-about-analyzers">TL;DR About Analyzers&lt;/h3>
&lt;p>To make a better use of &lt;code>text&lt;/code> data you can setup the &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analyzer-anatomy.html">analyzer&lt;/a> which is a combination of three components:&lt;/p>
&lt;ul>
&lt;li>exactly one &lt;strong>tokenizer&lt;/strong>,&lt;/li>
&lt;li>zero or more &lt;strong>character filters&lt;/strong>,&lt;/li>
&lt;li>zero or more &lt;strong>token filters&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;p>Basically, an analyzer transforms a single &lt;em>string&lt;/em> into &lt;em>words&lt;/em>, e.g. &lt;code>&amp;quot;This is my text&amp;quot;&lt;/code> can be transformed into &lt;code>[&amp;quot;this&amp;quot;, &amp;quot;my&amp;quot;, &amp;quot;text&amp;quot;]&lt;/code> which you can read as:&lt;/p>
&lt;ul>
&lt;li>text is split into tokens by tokenizer,&lt;/li>
&lt;li>each token is lowercased with the a token filter,&lt;/li>
&lt;li>stopwords are removed with another token filter.&lt;/li>
&lt;/ul>
&lt;h3 id="normalizers">Normalizers&lt;/h3>
&lt;p>The &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-normalizers.html">documentation&lt;/a> says that:&lt;/p>
&lt;blockquote>
&lt;p>Normalizers are similar to analyzers except that they may only emit a single token.&lt;/p>
&lt;/blockquote>
&lt;p>Normalizers can only be applied to the &lt;code>keyword&lt;/code> datatype. The cannonical use case is to lowercase structured content such as IDs, email addresses, e.g. a database stores emails in whatever case but searching for emails should be case insensitive. Note that only a subset of available filters can be used by a normalizer: all filters must work on a &lt;strong>per-character basis&lt;/strong>, i.e. no stopwords or stemmers.&lt;/p>
&lt;h3 id="normalizers-for-normalizing-url-data">Normalizers for Normalizing URL Data&lt;/h3>
&lt;p>Storing a URL in a &lt;code>keyword&lt;/code> field allows to filter, sort, and aggregate your data per URL. But what if you need to filter, sort, and aggregate by just one part of the URL and you have little to no control over the upstream data source? You have a couple of options:&lt;/p>
&lt;ul>
&lt;li>convince upstream to extract that one part in their code and send it to you,&lt;/li>
&lt;li>setup a &lt;code>text&lt;/code> field with an analyzer that produces just that one token and enable field data (not a default setup and can get expensive).&lt;/li>
&lt;li>setup a &lt;code>keyword&lt;/code> field with a normalizer with a &lt;code>char_filter&lt;/code>.&lt;/li>
&lt;li>give up.&lt;/li>
&lt;/ul>
&lt;p>I want to explore the &lt;code>keyword&lt;/code> option. In the next section I&amp;rsquo;ll show how to setup normalizers for Elasticsearch URLs.&lt;/p>
&lt;h3 id="the-not-so-synthetic-problem">The not so Synthetic Problem&lt;/h3>
&lt;p>We have a list URLs without a hostname that were used to query Elasticsearch, e.g.: &lt;code>/my_search_index/_search?q=elasticsearch&lt;/code> and we need to split URLs into parts such as: index, operation endpoint, e.g.: &lt;code>_search&lt;/code> or &lt;code>_count&lt;/code>, query filters, etc. In the following example I&amp;rsquo;ll focus on the extracting the index part of the URL.&lt;/p>
&lt;p>Let&amp;rsquo;s create an index:&lt;/p>
&lt;pre>&lt;code>PUT elasticsearch_url_index
{
&amp;quot;settings&amp;quot;: {
&amp;quot;index&amp;quot;: {
&amp;quot;analysis&amp;quot;: {
&amp;quot;normalizer&amp;quot;: {
&amp;quot;index_extractor_normalizer&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;custom&amp;quot;,
&amp;quot;char_filter&amp;quot;: [
&amp;quot;index_name_extractor&amp;quot;
]
}
},
&amp;quot;char_filter&amp;quot;: {
&amp;quot;index_name_extractor&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;pattern_replace&amp;quot;,
&amp;quot;pattern&amp;quot;: &amp;quot;/(.+)/.*&amp;quot;,
&amp;quot;replacement&amp;quot;: &amp;quot;$1&amp;quot;
}
}
}
}
},
&amp;quot;mappings&amp;quot; : {
&amp;quot;properties&amp;quot;: {
&amp;quot;url&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;,
&amp;quot;fields&amp;quot;: {
&amp;quot;index&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;,
&amp;quot;normalizer&amp;quot;: &amp;quot;index_extractor_normalizer&amp;quot;
}
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Here we setup the index with a normalizer &lt;code>index_extractor_normalizer&lt;/code> that has a char filter &lt;code>index_name_extractor&lt;/code> that uses a regex &lt;code>pattern_replace&lt;/code> to extract characters between the first and the second slashes. The mappings have a property &lt;code>url&lt;/code> which is of the &lt;code>keyword&lt;/code> type and have a field &lt;code>index&lt;/code> which is also of the &lt;code>keyword&lt;/code> type and is set up to use the normalizer &lt;code>index_extractor_normalizer&lt;/code>.&lt;/p>
&lt;p>Since the normalizer is basically a collection of filters we can use our good old friend &lt;code>_analyze&lt;/code> API to test how it works.&lt;/p>
&lt;pre>&lt;code>POST elasticsearch_url_index/_analyze
{
&amp;quot;char_filter&amp;quot;: [&amp;quot;index_name_extractor&amp;quot;],
&amp;quot;text&amp;quot;: [&amp;quot;/my_search_index/_search?q=elasticsearch&amp;quot;]
}
&lt;/code>&lt;/pre>
&lt;p>Produces:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;tokens&amp;quot; : [
{
&amp;quot;token&amp;quot; : &amp;quot;my_search_index&amp;quot;,
&amp;quot;start_offset&amp;quot; : 0,
&amp;quot;end_offset&amp;quot; : 40,
&amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
&amp;quot;position&amp;quot; : 0
}
]
}
&lt;/code>&lt;/pre>
&lt;p>Good, exactly as we wanted: &lt;code>/my_search_index/_search?q=elasticsearch&lt;/code> =&amp;gt; &lt;code>my_search_index&lt;/code>.&lt;/p>
&lt;p>Let&amp;rsquo;s index some data:&lt;/p>
&lt;pre>&lt;code>PUT elasticsearch_url_index/_doc/0
{
&amp;quot;url&amp;quot;: &amp;quot;/my_search_index/_search?q=elasticsearch&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>Let&amp;rsquo;s try to filter URLs by the index name:&lt;/p>
&lt;pre>&lt;code>GET elasticsearch_url_index/_search?q=url:my_search_index
&lt;/code>&lt;/pre>
&lt;p>Produces:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 0,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 0,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : null,
&amp;quot;hits&amp;quot; : [ ]
}
}
&lt;/code>&lt;/pre>
&lt;p>No results? What? Oh! Wrong field: &lt;code>url&lt;/code> was used instead of &lt;code>url.index&lt;/code>. Let&amp;rsquo;s try once again:&lt;/p>
&lt;pre>&lt;code>GET elasticsearch_url_index/_search?q=url.index:my_search_index
&lt;/code>&lt;/pre>
&lt;p>Produces:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.2876821,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;elasticsearch_url_index&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;0&amp;quot;,
&amp;quot;_score&amp;quot; : 0.2876821,
&amp;quot;_source&amp;quot; : {
&amp;quot;url&amp;quot; : &amp;quot;/my_search_index/_search?q=elasticsearch&amp;quot;
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>As expected. Cool.&lt;/p>
&lt;h3 id="bonus-a-trick-with-the-docvalue_fields">Bonus: a Trick with the &lt;code>docvalue_fields&lt;/code>&lt;/h3>
&lt;p>Another neat trick is that we can get out the &lt;code>index&lt;/code> part of the URL from an Elasticsearch index using the &lt;code>docvalue_fields&lt;/code> option in a request ,e.g.:&lt;/p>
&lt;pre>&lt;code>GET elasticsearch_url_index/_search?q=url.index:my_search_index
{
&amp;quot;docvalue_fields&amp;quot;: [&amp;quot;url.index&amp;quot;]
}
&lt;/code>&lt;/pre>
&lt;p>Produces:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.2876821,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;elasticsearch_url_index&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;0&amp;quot;,
&amp;quot;_score&amp;quot; : 0.2876821,
&amp;quot;_source&amp;quot; : {
&amp;quot;url&amp;quot; : &amp;quot;/my_search_index/_search?q=elasticsearch&amp;quot;
},
&amp;quot;fields&amp;quot; : {
&amp;quot;url.index&amp;quot; : [
&amp;quot;my_search_index&amp;quot;
]
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>The important part is this one:&lt;/p>
&lt;pre>&lt;code>&amp;quot;fields&amp;quot; : {
&amp;quot;url.index&amp;quot; : [
&amp;quot;my_search_index&amp;quot;
]
}
&lt;/code>&lt;/pre>
&lt;p>A neat thing about the &lt;code>docvalue_fields&lt;/code> is that in the example above the &lt;code>my_search_index&lt;/code> value is not comming from the &lt;code>_source&lt;/code> of the document. This means that we can use &lt;code>keywords&lt;/code> and by extension normalized &lt;code>keywords&lt;/code> to fetch an exact value from the Elasticsearch index and not necessarily the one that was sent to Elasticsearch which somewhat solves our dependency from the upstream systems.&lt;/p>
&lt;h2 id="notes">Notes&lt;/h2>
&lt;p>The setup is done in the Kibana Dev Tools with the Elasticsearch 7.7.0.&lt;/p>
&lt;p>The pattern &lt;code>&amp;quot;/(.+)/.*&amp;quot;&lt;/code> is a bit simplified purely for presentation purposes and doesn&amp;rsquo;t work as expected for URLs with more than 2 slashes, e.g.: &lt;code>/index/type/_search&lt;/code> would produce &lt;code>index/type&lt;/code>. You need something a bit more involved like &lt;code>&amp;quot;/([^/]+)/.*&amp;quot;&lt;/code>.&lt;/p>
&lt;h2 id="fin">Fin&lt;/h2>
&lt;p>That is all I wanted to show you today. Hope it might be useful/interesting to someone down the line. Leave comments on the Github issue &lt;a href="https://github.com/dainiusjocas/blog/issues/7">here&lt;/a>. Cheers!&lt;/p></description></item><item><title>Using Search Templates in Elasticsearch</title><link>https://www.jocas.lt/blog/post/on-search-templates/</link><pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate><guid>https://www.jocas.lt/blog/post/on-search-templates/</guid><description>&lt;p>I want to take a look at &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-template.html">Search Templates&lt;/a> for Elasticsearch. Let&amp;rsquo;s apply them to examples from &lt;a href="https://www.jocas.lt/blog/post/synonym-graph-phrase-search/">previous post on Synonym Graphs&lt;/a>.&lt;/p>
&lt;h2 id="setup">Setup&lt;/h2>
&lt;p>I&amp;rsquo;m using Elasticsearch 7.5.1.&lt;/p>
&lt;p>Index configuration:&lt;/p>
&lt;pre>&lt;code>DELETE test_index-1
PUT /test_index-1
{
&amp;quot;mappings&amp;quot;: {
&amp;quot;properties&amp;quot;: {
&amp;quot;descrition&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;
},
&amp;quot;entity&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
&amp;quot;analyzer&amp;quot;: &amp;quot;lowercase_keyword_analyzer&amp;quot;,
&amp;quot;search_analyzer&amp;quot;: &amp;quot;synonym_graph_analyzer&amp;quot;
}
}
},
&amp;quot;settings&amp;quot;: {
&amp;quot;index&amp;quot;: {
&amp;quot;analysis&amp;quot;: {
&amp;quot;analyzer&amp;quot;: {
&amp;quot;synonym_graph_analyzer&amp;quot;: {
&amp;quot;tokenizer&amp;quot;: &amp;quot;standard&amp;quot;,
&amp;quot;filter&amp;quot;: [
&amp;quot;lowercase&amp;quot;,
&amp;quot;my_synonym_graph&amp;quot;
]
},
&amp;quot;lowercase_keyword_analyzer&amp;quot;: {
&amp;quot;tokenizer&amp;quot;: &amp;quot;keyword&amp;quot;,
&amp;quot;filter&amp;quot;: [
&amp;quot;lowercase&amp;quot;
],
&amp;quot;char_filter&amp;quot;: [
&amp;quot;spaces_to_undescores_filter&amp;quot;
]
}
},
&amp;quot;char_filter&amp;quot;: {
&amp;quot;spaces_to_undescores_filter&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;mapping&amp;quot;,
&amp;quot;mappings&amp;quot;: [
&amp;quot; \\u0020 =&amp;gt; _&amp;quot;
]
}
},
&amp;quot;filter&amp;quot;: {
&amp;quot;my_synonym_graph&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;synonym_graph&amp;quot;,
&amp;quot;lenient&amp;quot;: true,
&amp;quot;synonyms&amp;quot;: [
&amp;quot;very important thing =&amp;gt; very_important_thing&amp;quot;
]
}
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Index the document:&lt;/p>
&lt;pre>&lt;code>PUT test_index-1/_doc/1
{
&amp;quot;description&amp;quot;: &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot;: &amp;quot;Very Important Thing&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>Search queries:&lt;/p>
&lt;ul>
&lt;li>&lt;code>prefix very important thing suffix&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="templates">Templates&lt;/h2>
&lt;p>I&amp;rsquo;m very interested in one particular use of the search templates: how flexible is the management of stored seach templates? Can I update a search template while receiving queries?&lt;/p>
&lt;p>Add a template:&lt;/p>
&lt;pre>&lt;code>POST _scripts/synonym-graph-search
{
&amp;quot;script&amp;quot;: {
&amp;quot;lang&amp;quot;: &amp;quot;mustache&amp;quot;,
&amp;quot;source&amp;quot;: {
&amp;quot;query&amp;quot;: {
&amp;quot;match&amp;quot;: {
&amp;quot;entity&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;{{query_string}}&amp;quot;,
&amp;quot;boost&amp;quot;: 2
}
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Try to run the search:&lt;/p>
&lt;pre>&lt;code>GET test_index-1/_search/template
{
&amp;quot;id&amp;quot;: &amp;quot;synonym-graph-search&amp;quot;,
&amp;quot;params&amp;quot;: {
&amp;quot;query_string&amp;quot;: &amp;quot;suffix very important thing prefix&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.5753642,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;test_index-1&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 0.5753642,
&amp;quot;_source&amp;quot; : {
&amp;quot;description&amp;quot; : &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot; : &amp;quot;Very Important Thing&amp;quot;
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>Exactly as expected.&lt;/p>
&lt;p>When using a stored search template the Elasticsearch client doesn&amp;rsquo;t need to handle the complex query construction.&lt;/p>
&lt;h2 id="templates-are-updateable">Templates are updateable&lt;/h2>
&lt;p>Let&amp;rsquo;s try to update the template with a higher boost value:&lt;/p>
&lt;pre>&lt;code>POST _scripts/synonym-graph-search
{
&amp;quot;script&amp;quot;: {
&amp;quot;lang&amp;quot;: &amp;quot;mustache&amp;quot;,
&amp;quot;source&amp;quot;: {
&amp;quot;query&amp;quot;: {
&amp;quot;match&amp;quot;: {
&amp;quot;entity&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;{{query_string}}&amp;quot;,
&amp;quot;boost&amp;quot;: 5
}
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Works.&lt;/p>
&lt;p>Now let&amp;rsquo;s run the same query:&lt;/p>
&lt;pre>&lt;code>GET test_index-1/_search/template
{
&amp;quot;id&amp;quot;: &amp;quot;synonym-graph-search&amp;quot;,
&amp;quot;params&amp;quot;: {
&amp;quot;query_string&amp;quot;: &amp;quot;suffix very important thing prefix&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 4,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 1.4384103,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;test_index-1&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 1.4384103,
&amp;quot;_source&amp;quot; : {
&amp;quot;description&amp;quot; : &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot; : &amp;quot;Very Important Thing&amp;quot;
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>The scores are 0.5753642 and 1.4384103 that is ~2/5. Cool! This means that without changing (and redeploying) the Elasticsearch client we can change the querying logic, making the query an more dynamic.&lt;/p>
&lt;h2 id="corner-cases">Corner Cases&lt;/h2>
&lt;p>What if we run query has more attributes, e.g.:&lt;/p>
&lt;pre>&lt;code>GET test_index-1/_search/template
{
&amp;quot;id&amp;quot;: &amp;quot;synonym-graph-search&amp;quot;,
&amp;quot;params&amp;quot;: {
&amp;quot;query_string&amp;quot;: &amp;quot;suffix very important thing prefix&amp;quot;,
&amp;quot;new_attr&amp;quot;: &amp;quot;123&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>Works as expected!&lt;/p>
&lt;p>When &lt;code>query_string&lt;/code> is &lt;code>null&lt;/code>:&lt;/p>
&lt;pre>&lt;code>GET test_index-1/_search/template
{
&amp;quot;id&amp;quot;: &amp;quot;synonym-graph-search&amp;quot;,
&amp;quot;params&amp;quot;: {
&amp;quot;query_string&amp;quot;: null
}
}
&lt;/code>&lt;/pre>
&lt;p>Works!&lt;/p>
&lt;p>What if the param is not provided:&lt;/p>
&lt;pre>&lt;code>GET test_index-1/_search/template
{
&amp;quot;id&amp;quot;: &amp;quot;synonym-graph-search&amp;quot;,
&amp;quot;params&amp;quot;: {
&amp;quot;new_attr&amp;quot;: &amp;quot;value&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>No error!&lt;/p>
&lt;p>What if we provide a list instead of a string:&lt;/p>
&lt;pre>&lt;code>GET test_index-1/_search/template
{
&amp;quot;id&amp;quot;: &amp;quot;synonym-graph-search&amp;quot;,
&amp;quot;params&amp;quot;: {
&amp;quot;query_string&amp;quot;: [&amp;quot;this&amp;quot;, &amp;quot;Very Important Thing&amp;quot;]
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 1.4384103,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;test_index-1&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 1.4384103,
&amp;quot;_source&amp;quot; : {
&amp;quot;description&amp;quot; : &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot; : &amp;quot;Very Important Thing&amp;quot;
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>Instead of profiding one value we can replace it with a list. Good!&lt;/p>
&lt;h2 id="metadata-of-the-search-template">Metadata of the search template&lt;/h2>
&lt;p>It would be great to be able to store some metadata with the search template script, e.g. Git commit SHA of the query. I couldn&amp;rsquo;t find a way to do this. A workaround might be to &lt;code>_name&lt;/code> attribute of the query. E.g.:&lt;/p>
&lt;pre>&lt;code>POST _scripts/synonym-graph-search
{
&amp;quot;script&amp;quot;: {
&amp;quot;lang&amp;quot;: &amp;quot;mustache&amp;quot;,
&amp;quot;source&amp;quot;: {
&amp;quot;query&amp;quot;: {
&amp;quot;match&amp;quot;: {
&amp;quot;entity&amp;quot;: {
&amp;quot;_name&amp;quot;: &amp;quot;GIT COMMIT SHA&amp;quot;,
&amp;quot;query&amp;quot;: &amp;quot;{{query_string}}&amp;quot;,
&amp;quot;boost&amp;quot;: 5
}
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>The response:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 1.4384103,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;test_index-1&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 1.4384103,
&amp;quot;_source&amp;quot; : {
&amp;quot;description&amp;quot; : &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot; : &amp;quot;Very Important Thing&amp;quot;
},
&amp;quot;matched_queries&amp;quot; : [
&amp;quot;GIT COMMIT SHA&amp;quot;
]
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>Not great but might be useful.&lt;/p>
&lt;h2 id="discussion">Discussion&lt;/h2>
&lt;ul>
&lt;li>Templates doesn&amp;rsquo;t support search index specification.&lt;/li>
&lt;li>Field names can be parameterized, this feature alows to start/stop using a new/old field.&lt;/li>
&lt;li>Search template can be tested in (even in production cluster) independently.&lt;/li>
&lt;li>We can run our query against &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/multi-search-template.html">multiple search templates&lt;/a>. Combine this with the Profile API and performance can be compared. Explain API also is supported.&lt;/li>
&lt;/ul></description></item><item><title>Phrase Search with Synonym Graph Token Filter in Elasticsearch</title><link>https://www.jocas.lt/blog/post/synonym-graph-phrase-search/</link><pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate><guid>https://www.jocas.lt/blog/post/synonym-graph-phrase-search/</guid><description>&lt;p>I&amp;rsquo;ve &lt;a href="https://www.jocas.lt/blog/post/es-percolator-phrase-highlight/">written&lt;/a> that if you google for &lt;code>How can you match a long query text to a short text field?&lt;/code> you&amp;rsquo;re advised to use Elasticsearch Percolator. Today I&amp;rsquo;ll show an alternative way of solving the same problem with Elasticsearch.&lt;/p>
&lt;p>The main idea is to use &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/analysis-synonym-graph-tokenfilter.html">Synonym Graph Token Filter&lt;/a> with some data preparation.&lt;/p>
&lt;h2 id="problem-statement">Problem Statement&lt;/h2>
&lt;p>Say that we learned how extract some entity from free form text with techniques such as NER, dictionary annotations, or some fancy Machine Learning. And when this entity is mentioned in the search query we want to boost documents that mention this entity. Also, say you&amp;rsquo;ve ruled out using Elasticsearch Percolator because it increases network latency because it requires additional call to Elasticsearch.&lt;/p>
&lt;p>For further discussion our unstructured text is going to be &lt;code>This description is about a Very Important Thing and something else.&lt;/code> and the extracted entity &lt;code>Very Important Thing&lt;/code>. Our test document looks like :&lt;/p>
&lt;pre>&lt;code class="language-json">{
&amp;quot;description&amp;quot;: &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot;: &amp;quot;Very Important Thing&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>Search queries:&lt;/p>
&lt;ul>
&lt;li>&lt;code>prefix very important thing suffix&lt;/code>&lt;/li>
&lt;li>&lt;code>prefix very important another thing suffix&lt;/code>&lt;/li>
&lt;li>&lt;code>prefix thing suffix&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>All examples are tested on Elasticsearch 7.5.1.&lt;/p>
&lt;h3 id="naive-setup">Naive Setup&lt;/h3>
&lt;p>Let&amp;rsquo;s create an index for our documents:&lt;/p>
&lt;pre>&lt;code>PUT /test_index-2
{
&amp;quot;mappings&amp;quot;: {
&amp;quot;properties&amp;quot;: {
&amp;quot;description&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;
},
&amp;quot;entity&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Entity field is of type &lt;code>text&lt;/code> because we want it to be searchable. &lt;code>keyword&lt;/code> type won&amp;rsquo;t work because it does only exact matches and out query most likely will be longer than our entity string.&lt;/p>
&lt;p>Index our document:&lt;/p>
&lt;pre>&lt;code>PUT test_index-2/_doc/1
{
&amp;quot;description&amp;quot;: &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot;: &amp;quot;Very Important Thing&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>Search the index with the query that mentions our &lt;code>very important thing&lt;/code>:&lt;/p>
&lt;pre>&lt;code>GET test_index-2/_search
{
&amp;quot;query&amp;quot;: {
&amp;quot;match&amp;quot;: {
&amp;quot;entity&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;prefix very important thing suffix&amp;quot;,
&amp;quot;boost&amp;quot;: 2
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 1.7260926,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;test_index-2&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 1.7260926,
&amp;quot;_source&amp;quot; : {
&amp;quot;description&amp;quot; : &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot; : &amp;quot;Very Important Thing&amp;quot;
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>Cool, we found what we we looking for.&lt;/p>
&lt;p>Let&amp;rsquo;s try another query, this time with a mention of &lt;code>very important another thing&lt;/code>:&lt;/p>
&lt;pre>&lt;code>GET test_index-2/_search
{
&amp;quot;query&amp;quot;: {
&amp;quot;match&amp;quot;: {
&amp;quot;entity&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;prefix very important another thing suffix&amp;quot;,
&amp;quot;boost&amp;quot;: 2
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 1.7260926,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;test_index-2&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 1.7260926,
&amp;quot;_source&amp;quot; : {
&amp;quot;description&amp;quot; : &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot; : &amp;quot;Very Important Thing&amp;quot;
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>Oh, the results are the same as with the previous query despite the fact that we mention &lt;code>Another Thing&lt;/code> here. But it still might be OK because we matched all the terms of the entity.&lt;/p>
&lt;p>Let&amp;rsquo;s try another query:&lt;/p>
&lt;pre>&lt;code>GET test_index-2/_search
{
&amp;quot;query&amp;quot;: {
&amp;quot;match&amp;quot;: {
&amp;quot;entity&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;prefix thing suffix&amp;quot;,
&amp;quot;boost&amp;quot;: 2
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.5753642,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;test_index-2&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 0.5753642,
&amp;quot;_source&amp;quot; : {
&amp;quot;description&amp;quot; : &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot; : &amp;quot;Very Important Thing&amp;quot;
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>Oh no, we still matched our &lt;code>Very Important Thing&lt;/code> while only &lt;code>thing&lt;/code> term is present in the query. But at least this time the score is lower than with previous twoqueries, 0.5753642 vs. 1.7260926. Here we clearly see the problem: we are matching short strings with long strings and partial matches raises problems.&lt;/p>
&lt;h2 id="proposed-solution">Proposed Solution&lt;/h2>
&lt;p>Let&amp;rsquo;s leverage Synonym Graph Token Filter to solve our problem.&lt;/p>
&lt;pre>&lt;code>PUT /test_index-1
{
&amp;quot;mappings&amp;quot;: {
&amp;quot;properties&amp;quot;: {
&amp;quot;descrition&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;
},
&amp;quot;entity&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
&amp;quot;analyzer&amp;quot;: &amp;quot;lowercase_keyword_analyzer&amp;quot;,
&amp;quot;search_analyzer&amp;quot;: &amp;quot;synonym_graph_analyzer&amp;quot;
}
}
},
&amp;quot;settings&amp;quot;: {
&amp;quot;index&amp;quot;: {
&amp;quot;analysis&amp;quot;: {
&amp;quot;analyzer&amp;quot;: {
&amp;quot;synonym_graph_analyzer&amp;quot;: {
&amp;quot;tokenizer&amp;quot;: &amp;quot;standard&amp;quot;,
&amp;quot;filter&amp;quot;: [
&amp;quot;lowercase&amp;quot;,
&amp;quot;my_synonym_graph&amp;quot;
]
},
&amp;quot;lowercase_keyword_analyzer&amp;quot;: {
&amp;quot;tokenizer&amp;quot;: &amp;quot;keyword&amp;quot;,
&amp;quot;filter&amp;quot;: [
&amp;quot;lowercase&amp;quot;
],
&amp;quot;char_filter&amp;quot;: [
&amp;quot;spaces_to_undescores_filter&amp;quot;
]
}
},
&amp;quot;char_filter&amp;quot;: {
&amp;quot;spaces_to_undescores_filter&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;mapping&amp;quot;,
&amp;quot;mappings&amp;quot;: [
&amp;quot; \\u0020 =&amp;gt; _&amp;quot;
]
}
},
&amp;quot;filter&amp;quot;: {
&amp;quot;my_synonym_graph&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;synonym_graph&amp;quot;,
&amp;quot;lenient&amp;quot;: true,
&amp;quot;synonyms&amp;quot;: [
&amp;quot;very important thing =&amp;gt; very_important_thing&amp;quot;
]
}
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Let&amp;rsquo;s decompose this large index configuration piece by piece:&lt;/p>
&lt;ol>
&lt;li>The &lt;code>entity&lt;/code> attribute now has separate analyzers for both index and search phases.&lt;/li>
&lt;li>The &lt;code>lowercase_keyword_analyzer&lt;/code> uses keyword tokenizer which means that tokenization will result in the sequence of token of size 1, then it normalizes tokens by lowercasing them and finally &lt;code>spaces_to_undescores_filter&lt;/code>, replaces spaces to underscores. E.g. a string &lt;code>&amp;quot;Very Important Thing&amp;quot;&lt;/code> is transformed into list of tokens &lt;code>[&amp;quot;very_important_thing&amp;quot;]&lt;/code>. Or use out friend &lt;code>_analyze&lt;/code> API:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>POST test_index-1/_analyze
{
&amp;quot;text&amp;quot;: [&amp;quot;Very Important Thing&amp;quot;],
&amp;quot;analyzer&amp;quot;: &amp;quot;lowercase_keyword_analyzer&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;tokens&amp;quot; : [
{
&amp;quot;token&amp;quot; : &amp;quot;very_important_thing&amp;quot;,
&amp;quot;start_offset&amp;quot; : 0,
&amp;quot;end_offset&amp;quot; : 20,
&amp;quot;type&amp;quot; : &amp;quot;word&amp;quot;,
&amp;quot;position&amp;quot; : 0
}
]
}
&lt;/code>&lt;/pre>
&lt;ol start="3">
&lt;li>The &lt;code>synonym_graph_analyzer&lt;/code> use standard tokenizer, which is followed by the &lt;code>lowercase&lt;/code> filter, and then the &lt;code>my_synonym_graph&lt;/code> token filter is applied. We&amp;rsquo;ve set up one synonym &lt;code>&amp;quot;very important thing =&amp;gt; very_important_thing&amp;quot;&lt;/code>. E.g.&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>POST test_index-1/_analyze
{
&amp;quot;text&amp;quot;: [&amp;quot;prefix very important thing suffix&amp;quot;],
&amp;quot;analyzer&amp;quot;: &amp;quot;synonym_graph_analyzer&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;tokens&amp;quot; : [
{
&amp;quot;token&amp;quot; : &amp;quot;prefix&amp;quot;,
&amp;quot;start_offset&amp;quot; : 0,
&amp;quot;end_offset&amp;quot; : 6,
&amp;quot;type&amp;quot; : &amp;quot;&amp;lt;ALPHANUM&amp;gt;&amp;quot;,
&amp;quot;position&amp;quot; : 0
},
{
&amp;quot;token&amp;quot; : &amp;quot;very_important_thing&amp;quot;,
&amp;quot;start_offset&amp;quot; : 7,
&amp;quot;end_offset&amp;quot; : 27,
&amp;quot;type&amp;quot; : &amp;quot;SYNONYM&amp;quot;,
&amp;quot;position&amp;quot; : 1
},
{
&amp;quot;token&amp;quot; : &amp;quot;suffix&amp;quot;,
&amp;quot;start_offset&amp;quot; : 28,
&amp;quot;end_offset&amp;quot; : 34,
&amp;quot;type&amp;quot; : &amp;quot;&amp;lt;ALPHANUM&amp;gt;&amp;quot;,
&amp;quot;position&amp;quot; : 2
}
]
}
&lt;/code>&lt;/pre>
&lt;p>After analysis we have 3 tokens &lt;code>[&amp;quot;prefix&amp;quot;, &amp;quot;very_important_thing&amp;quot;, &amp;quot;suffix&amp;quot;]&lt;/code>. Notice &lt;code>&amp;quot;very_important_thing&amp;quot;&lt;/code> token: this is equal to the right-hand-side from our synonym definitions. Now let&amp;rsquo;s run queries from the previous section:&lt;/p>
&lt;pre>&lt;code>GET test_index-1/_search
{
&amp;quot;query&amp;quot;: {
&amp;quot;match&amp;quot;: {
&amp;quot;entity&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;prefix very important thing suffix&amp;quot;,
&amp;quot;boost&amp;quot;: 2
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.5753642,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;test_index-1&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 0.5753642,
&amp;quot;_source&amp;quot; : {
&amp;quot;description&amp;quot; : &amp;quot;This description is about a Very Important Thing and something else.&amp;quot;,
&amp;quot;entity&amp;quot; : &amp;quot;Very Important Thing&amp;quot;
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>As expected: exact match -&amp;gt; hit.&lt;/p>
&lt;p>Another query:&lt;/p>
&lt;pre>&lt;code>GET test_index-1/_search
{
&amp;quot;query&amp;quot;: {
&amp;quot;match&amp;quot;: {
&amp;quot;entity&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;prefix very important another thing suffix&amp;quot;,
&amp;quot;boost&amp;quot;: 2
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 0,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 0,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : null,
&amp;quot;hits&amp;quot; : [ ]
}
}
&lt;/code>&lt;/pre>
&lt;p>No hits! Good! The document is not going to be boosted despite the fact that all tokens match.&lt;/p>
&lt;p>And the last one:&lt;/p>
&lt;pre>&lt;code>GET test_index-1/_search
{
&amp;quot;query&amp;quot;: {
&amp;quot;match&amp;quot;: {
&amp;quot;entity&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;prefix thing suffix&amp;quot;,
&amp;quot;boost&amp;quot;: 2
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 0,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : null,
&amp;quot;hits&amp;quot; : [ ]
}
}
&lt;/code>&lt;/pre>
&lt;p>No hits! Good. This means that also substring doesn&amp;rsquo;t match.&lt;/p>
&lt;h2 id="discussion">Discussion&lt;/h2>
&lt;p>Synonym Graph Token Filter can &amp;ldquo;replace&amp;rdquo; a sequence of tokens (e.g. a phrase) with another sequence of tokens. In this particular example: many tokens were replaced with one token.&lt;/p>
&lt;ol>
&lt;li>One field can have only one analyzer pair for index and search phases. If we want another analysis pipeline for the &lt;code>entity&lt;/code> attribute we have to create another field with the analyzers specified, e.g. stemmed phrase with lower boost.&lt;/li>
&lt;li>The synonym list must be prepared before the index creation.&lt;/li>
&lt;li>Management of the synonym list might complicate index management, e.g. you use templates for your index management.&lt;/li>
&lt;li>The overal solution in general might look a bit too complicated.&lt;/li>
&lt;/ol></description></item><item><title>Elasticsearch Percolator and Text Analyzers</title><link>https://www.jocas.lt/blog/post/percolator-phrase-analyzers/</link><pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate><guid>https://www.jocas.lt/blog/post/percolator-phrase-analyzers/</guid><description>&lt;p>This time I need to percolate texts with different analyzers for index and search analyzers.&lt;/p>
&lt;p>Let&amp;rsquo;s elaborate a bit on &lt;a href="https://www.jocas.lt/blog/post/es-percolator-phrase-highlight/">previous article&lt;/a> and explicitly declare analyzers to use.&lt;/p>
&lt;p>Define index:&lt;/p>
&lt;pre>&lt;code>PUT /my-index
{
&amp;quot;mappings&amp;quot;: {
&amp;quot;properties&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
&amp;quot;analyzer&amp;quot;: &amp;quot;standard&amp;quot;,
&amp;quot;term_vector&amp;quot;: &amp;quot;with_positions_offsets&amp;quot;
},
&amp;quot;query&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;percolator&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Then define 2 slightly different percolator queries (notice the difference between &lt;code>&amp;quot;bonsai tree&amp;quot;&lt;/code> and &lt;code>&amp;quot;bonsai, tree&amp;quot;&lt;/code>).&lt;/p>
&lt;pre>&lt;code>PUT /my-index/_doc/1?refresh
{
&amp;quot;query&amp;quot;: {
&amp;quot;match_phrase&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;bonsai tree&amp;quot;,
&amp;quot;analyzer&amp;quot;: &amp;quot;standard&amp;quot;
}
}
}
}
PUT /my-index/_doc/2?refresh
{
&amp;quot;query&amp;quot;: {
&amp;quot;match_phrase&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;bonsai, tree&amp;quot;,
&amp;quot;analyzer&amp;quot;: &amp;quot;standard&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Let&amp;rsquo;s percolate:&lt;/p>
&lt;pre>&lt;code>GET /my-index/_search?
{
&amp;quot;query&amp;quot;: {
&amp;quot;percolate&amp;quot;: {
&amp;quot;field&amp;quot;: &amp;quot;query&amp;quot;,
&amp;quot;document&amp;quot;: {
&amp;quot;message&amp;quot;: &amp;quot;A new bonsai tree in the office&amp;quot;
}
}
},
&amp;quot;highlight&amp;quot;: {
&amp;quot;fields&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;fvh&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 80,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 2,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.26152915,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;my-index&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;2&amp;quot;,
&amp;quot;_score&amp;quot; : 0.26152915,
&amp;quot;_source&amp;quot; : {
&amp;quot;query&amp;quot; : {
&amp;quot;match_phrase&amp;quot; : {
&amp;quot;message&amp;quot; : {
&amp;quot;query&amp;quot; : &amp;quot;bonsai, tree&amp;quot;,
&amp;quot;analyzer&amp;quot; : &amp;quot;standard&amp;quot;
}
}
}
},
&amp;quot;fields&amp;quot; : {
&amp;quot;_percolator_document_slot&amp;quot; : [
0
]
},
&amp;quot;highlight&amp;quot; : {
&amp;quot;message&amp;quot; : [
&amp;quot;A new &amp;lt;em&amp;gt;bonsai tree&amp;lt;/em&amp;gt; in the office&amp;quot;
]
}
},
{
&amp;quot;_index&amp;quot; : &amp;quot;my-index&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 0.26152915,
&amp;quot;_source&amp;quot; : {
&amp;quot;query&amp;quot; : {
&amp;quot;match_phrase&amp;quot; : {
&amp;quot;message&amp;quot; : {
&amp;quot;query&amp;quot; : &amp;quot;bonsai tree&amp;quot;,
&amp;quot;analyzer&amp;quot; : &amp;quot;standard&amp;quot;
}
}
}
},
&amp;quot;fields&amp;quot; : {
&amp;quot;_percolator_document_slot&amp;quot; : [
0
]
},
&amp;quot;highlight&amp;quot; : {
&amp;quot;message&amp;quot; : [
&amp;quot;A new &amp;lt;em&amp;gt;bonsai tree&amp;lt;/em&amp;gt; in the office&amp;quot;
]
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>As expected: 2 documents matched.&lt;/p>
&lt;p>But now lets change the analyzer of the second percolation query to &lt;code>whitespace&lt;/code>:&lt;/p>
&lt;pre>&lt;code>PUT /my-index/_doc/2?refresh
{
&amp;quot;query&amp;quot;: {
&amp;quot;match_phrase&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;bonsai, tree&amp;quot;,
&amp;quot;analyzer&amp;quot;: &amp;quot;whitespace&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Run the percolator:&lt;/p>
&lt;pre>&lt;code>
GET /my-index/_search?
{
&amp;quot;query&amp;quot;: {
&amp;quot;percolate&amp;quot;: {
&amp;quot;field&amp;quot;: &amp;quot;query&amp;quot;,
&amp;quot;document&amp;quot;: {
&amp;quot;message&amp;quot;: &amp;quot;A new bonsai tree in the office&amp;quot;
}
}
},
&amp;quot;highlight&amp;quot;: {
&amp;quot;fields&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;fvh&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 5,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.26152915,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;my-index&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 0.26152915,
&amp;quot;_source&amp;quot; : {
&amp;quot;query&amp;quot; : {
&amp;quot;match_phrase&amp;quot; : {
&amp;quot;message&amp;quot; : {
&amp;quot;query&amp;quot; : &amp;quot;bonsai tree&amp;quot;,
&amp;quot;analyzer&amp;quot; : &amp;quot;standard&amp;quot;
}
}
}
},
&amp;quot;fields&amp;quot; : {
&amp;quot;_percolator_document_slot&amp;quot; : [
0
]
},
&amp;quot;highlight&amp;quot; : {
&amp;quot;message&amp;quot; : [
&amp;quot;A new &amp;lt;em&amp;gt;bonsai tree&amp;lt;/em&amp;gt; in the office&amp;quot;
]
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>As expected: only 1 percolator query matched our input.&lt;/p>
&lt;h2 id="phrases-with-stopwords">Phrases with Stopwords&lt;/h2>
&lt;p>Say, we have a phrase &lt;code>&amp;quot;bonsai is tree&amp;quot;&lt;/code> and we percolate text &lt;code>A new bonsai in tree in the office&lt;/code> with the &lt;code>standard&lt;/code> analyzer for indexing and &lt;code>english&lt;/code> for search analyzer. There should be no matches. Let&amp;rsquo;s try:&lt;/p>
&lt;pre>&lt;code>DELETE my-index
PUT /my-index
{
&amp;quot;mappings&amp;quot;: {
&amp;quot;properties&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
&amp;quot;analyzer&amp;quot;: &amp;quot;standard&amp;quot;,
&amp;quot;search_analyzer&amp;quot;: &amp;quot;english&amp;quot;,
&amp;quot;term_vector&amp;quot;: &amp;quot;with_positions_offsets&amp;quot;
},
&amp;quot;query&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;percolator&amp;quot;
}
}
}
}
PUT /my-index/_doc/1?refresh
{
&amp;quot;query&amp;quot;: {
&amp;quot;match_phrase&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;bonsai is tree&amp;quot;
}
}
}
}
GET /my-index/_search?
{
&amp;quot;query&amp;quot;: {
&amp;quot;percolate&amp;quot;: {
&amp;quot;field&amp;quot;: &amp;quot;query&amp;quot;,
&amp;quot;document&amp;quot;: {
&amp;quot;message&amp;quot;: &amp;quot;A new bonsai in tree in the office&amp;quot;
}
}
},
&amp;quot;highlight&amp;quot;: {
&amp;quot;fields&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;fvh&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>And, surprisingly, this yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 2,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.26152915,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;my-index&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 0.26152915,
&amp;quot;_source&amp;quot; : {
&amp;quot;query&amp;quot; : {
&amp;quot;match_phrase&amp;quot; : {
&amp;quot;message&amp;quot; : {
&amp;quot;query&amp;quot; : &amp;quot;bonsai is tree&amp;quot;
}
}
}
},
&amp;quot;fields&amp;quot; : {
&amp;quot;_percolator_document_slot&amp;quot; : [
0
]
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>We have a match! Also notice that the highlighter is broken!&lt;/p>
&lt;p>The problem that these two analyzers have different stopword lists (no stopwords for &lt;code>standard&lt;/code> and several English stopwords for &lt;code>english&lt;/code> analyzer) and the phrase contains a stopword that is not shared between analyzers.&lt;/p>
&lt;p>Let&amp;rsquo;s fix this surprise with &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analyzer.html#search-quote-analyzer">&lt;code>search_quote_analyzer&lt;/code>&lt;/a>.&lt;/p>
&lt;pre>&lt;code>DELETE my-index
PUT /my-index
{
&amp;quot;mappings&amp;quot;: {
&amp;quot;properties&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
&amp;quot;analyzer&amp;quot;: &amp;quot;standard&amp;quot;,
&amp;quot;search_analyzer&amp;quot;: &amp;quot;english&amp;quot;,
&amp;quot;search_quote_analyzer&amp;quot;: &amp;quot;standard&amp;quot;,
&amp;quot;term_vector&amp;quot;: &amp;quot;with_positions_offsets&amp;quot;
},
&amp;quot;query&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;percolator&amp;quot;
}
}
}
}
PUT /my-index/_doc/1?refresh
{
&amp;quot;query&amp;quot;: {
&amp;quot;match_phrase&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;query&amp;quot;: &amp;quot;bonsai is tree&amp;quot;
}
}
}
}
GET /my-index/_search?
{
&amp;quot;query&amp;quot;: {
&amp;quot;percolate&amp;quot;: {
&amp;quot;field&amp;quot;: &amp;quot;query&amp;quot;,
&amp;quot;document&amp;quot;: {
&amp;quot;message&amp;quot;: &amp;quot;A new bonsai in tree in the office&amp;quot;
}
}
},
&amp;quot;highlight&amp;quot;: {
&amp;quot;fields&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;fvh&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 1,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 0,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : null,
&amp;quot;hits&amp;quot; : [ ]
}
}
&lt;/code>&lt;/pre>
&lt;p>No hits, as expected.&lt;/p>
&lt;p>Let&amp;rsquo;s check if the expected behaviour is still there:&lt;/p>
&lt;pre>&lt;code>GET /my-index/_search?
{
&amp;quot;query&amp;quot;: {
&amp;quot;percolate&amp;quot;: {
&amp;quot;field&amp;quot;: &amp;quot;query&amp;quot;,
&amp;quot;document&amp;quot;: {
&amp;quot;message&amp;quot;: &amp;quot;A new bonsai is tree in the office&amp;quot;
}
}
},
&amp;quot;highlight&amp;quot;: {
&amp;quot;fields&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;fvh&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 4,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.39229375,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;my-index&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 0.39229375,
&amp;quot;_source&amp;quot; : {
&amp;quot;query&amp;quot; : {
&amp;quot;match_phrase&amp;quot; : {
&amp;quot;message&amp;quot; : {
&amp;quot;query&amp;quot; : &amp;quot;bonsai is tree&amp;quot;
}
}
}
},
&amp;quot;fields&amp;quot; : {
&amp;quot;_percolator_document_slot&amp;quot; : [
0
]
},
&amp;quot;highlight&amp;quot; : {
&amp;quot;message&amp;quot; : [
&amp;quot;A new &amp;lt;em&amp;gt;bonsai is tree&amp;lt;/em&amp;gt; in the office&amp;quot;
]
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>Good. Even the highlighting works.&lt;/p></description></item><item><title>Phrase Highlighting with the Elasticsearch Percolator</title><link>https://www.jocas.lt/blog/post/es-percolator-phrase-highlight/</link><pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate><guid>https://www.jocas.lt/blog/post/es-percolator-phrase-highlight/</guid><description>&lt;p>If you google &lt;code>How can you match a long query text to a short text field?&lt;/code> it will point you to the &lt;a href="https://stackoverflow.com/questions/51865747/elasticsearch-match-long-query-text-to-short-field">Stack Overflow page&lt;/a> &lt;a href="https://discuss.elastic.co/t/match-long-query-text-to-short-field/144584/3">or here&lt;/a> where the answer is to use &lt;a href="">Elasticsearch Percolator&lt;/a>.&lt;/p>
&lt;p>My search items are phrases meaning that it should match all terms in order. Let&amp;rsquo;s create a sample setup in Kibana (v7.5) Dev dashboard.&lt;/p>
&lt;ol>
&lt;li>Create an index for percolation:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>PUT /my-index
{
&amp;quot;mappings&amp;quot;: {
&amp;quot;properties&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
&amp;quot;term_vector&amp;quot;: &amp;quot;with_positions_offsets&amp;quot;
},
&amp;quot;query&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;percolator&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Note on &lt;code>&amp;quot;term_vector&amp;quot;: &amp;quot;with_positions_offsets&amp;quot;&lt;/code>: this allows &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.6/search-request-highlighting.html#fast-vector-highlighter">Fast Vector Highlighter&lt;/a> to highlight combined phrase not just separate qeury terms.&lt;/p>
&lt;ol start="2">
&lt;li>Store one phrase query:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>PUT /my-index/_doc/1?refresh
{
&amp;quot;query&amp;quot;: {
&amp;quot;match_phrase&amp;quot;: {
&amp;quot;message&amp;quot;: &amp;quot;bonsai tree&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;ol start="3">
&lt;li>Percolate a document:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>GET /my-index/_search?
{
&amp;quot;query&amp;quot;: {
&amp;quot;percolate&amp;quot;: {
&amp;quot;field&amp;quot;: &amp;quot;query&amp;quot;,
&amp;quot;document&amp;quot;: {
&amp;quot;message&amp;quot;: &amp;quot;A new bonsai tree in the office&amp;quot;
}
}
},
&amp;quot;highlight&amp;quot;: {
&amp;quot;fields&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;fvh&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>Note on &lt;code>&amp;quot;type&amp;quot;: &amp;quot;fvh&amp;quot;&lt;/code>: this instructs Elasticsearch to use the Fast Vector Highlighter.&lt;/p>
&lt;p>The query yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 23,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.26152915,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;my-index&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 0.26152915,
&amp;quot;_source&amp;quot; : {
&amp;quot;query&amp;quot; : {
&amp;quot;match_phrase&amp;quot; : {
&amp;quot;message&amp;quot; : &amp;quot;bonsai tree&amp;quot;
}
}
},
&amp;quot;fields&amp;quot; : {
&amp;quot;_percolator_document_slot&amp;quot; : [
0
]
},
&amp;quot;highlight&amp;quot; : {
&amp;quot;message&amp;quot; : [
&amp;quot;A new &amp;lt;em&amp;gt;bonsai tree&amp;lt;/em&amp;gt; in the office&amp;quot;
]
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>As we see highlighter correctly marker the search phrase.&lt;/p>
&lt;h2 id="storing-additional-data-with-percolator-queries">Storing additional data with percolator queries&lt;/h2>
&lt;p>Percolation result can be used to connect pieces of information in your system, e.g. store a &lt;code>subscriber_email&lt;/code> attribute of the user that wants to be notified when the query matches along with the percolator query.&lt;/p>
&lt;pre>&lt;code>PUT /my-index/_doc/1?refresh
{
&amp;quot;query&amp;quot;: {
&amp;quot;match_phrase&amp;quot;: {
&amp;quot;message&amp;quot;: &amp;quot;bonsai tree&amp;quot;
}
},
&amp;quot;subscriber_email&amp;quot;: &amp;quot;subscriber_email@example.com&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>Then query:&lt;/p>
&lt;pre>&lt;code>GET /my-index/_search?
{
&amp;quot;query&amp;quot;: {
&amp;quot;percolate&amp;quot;: {
&amp;quot;field&amp;quot;: &amp;quot;query&amp;quot;,
&amp;quot;document&amp;quot;: {
&amp;quot;message&amp;quot;: &amp;quot;A new bonsai tree in the office&amp;quot;
}
}
},
&amp;quot;highlight&amp;quot;: {
&amp;quot;fields&amp;quot;: {
&amp;quot;message&amp;quot;: {
&amp;quot;type&amp;quot;: &amp;quot;fvh&amp;quot;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This query yields:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;took&amp;quot; : 10,
&amp;quot;timed_out&amp;quot; : false,
&amp;quot;_shards&amp;quot; : {
&amp;quot;total&amp;quot; : 1,
&amp;quot;successful&amp;quot; : 1,
&amp;quot;skipped&amp;quot; : 0,
&amp;quot;failed&amp;quot; : 0
},
&amp;quot;hits&amp;quot; : {
&amp;quot;total&amp;quot; : {
&amp;quot;value&amp;quot; : 1,
&amp;quot;relation&amp;quot; : &amp;quot;eq&amp;quot;
},
&amp;quot;max_score&amp;quot; : 0.26152915,
&amp;quot;hits&amp;quot; : [
{
&amp;quot;_index&amp;quot; : &amp;quot;my-index&amp;quot;,
&amp;quot;_type&amp;quot; : &amp;quot;_doc&amp;quot;,
&amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
&amp;quot;_score&amp;quot; : 0.26152915,
&amp;quot;_source&amp;quot; : {
&amp;quot;query&amp;quot; : {
&amp;quot;match_phrase&amp;quot; : {
&amp;quot;message&amp;quot; : &amp;quot;bonsai tree&amp;quot;
}
},
&amp;quot;subscriber_email&amp;quot; : &amp;quot;subscriber_email@example.com&amp;quot;
},
&amp;quot;fields&amp;quot; : {
&amp;quot;_percolator_document_slot&amp;quot; : [
0
]
},
&amp;quot;highlight&amp;quot; : {
&amp;quot;message&amp;quot; : [
&amp;quot;A new &amp;lt;em&amp;gt;bonsai tree&amp;lt;/em&amp;gt; in the office&amp;quot;
]
}
}
]
}
}
&lt;/code>&lt;/pre>
&lt;p>Now, take the email under the &lt;code>&amp;quot;subscriber_email&amp;quot;&lt;/code> from the response and send an email with the highlight.&lt;/p></description></item></channel></rss>