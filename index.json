[{"authors":["admin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://www.jocas.lt/blog/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/blog/authors/admin/","section":"authors","summary":"","tags":null,"title":"Dainius Jocas","type":"authors"},{"authors":["Dainius Jocas"],"categories":["elasticsearch"],"content":"I've written that if you google for How can you match a long query text to a short text field? you're advised to use Elasticsearch Percolator. Today I'll show an alternative way of solving the same problem with Elasticsearch.\nThe main idea is to use Synonym Graph Token Filter with some data preparation.\nProblem Statement Say that we learned how extract some entity from free form text with techniques such as NER, dictionary annotations, or some fancy Machine Learning. And when this entity is mentioned in the search query we want to boost documents that mention this entity. Also, say you've ruled out using Elasticsearch Percolator because it increases network latency because it requires additional call to Elasticsearch.\nFor further discussion our unstructured text is going to be This description is about a Very Important Thing and something else. and the extracted entity Very Important Thing. Our test document looks like :\n{ \u0026#34;description\u0026#34;: \u0026#34;This description is about a Very Important Thing and something else.\u0026#34;, \u0026#34;entity\u0026#34;: \u0026#34;Very Important Thing\u0026#34; } Search queries:\n prefix very important thing suffix prefix very important another thing suffix prefix thing suffix  All examples are tested on Elasticsearch 7.5.1.\nNaive Setup Let's create an index for our documents:\nPUT /test_index-2 { \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;description\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; }, \u0026quot;entity\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } } } Entity field is of type text because we want it to be searchable. keyword type won't work because it does only exact matches and out query most likely will be longer than our entity string.\nIndex our document:\nPUT test_index-2/_doc/1 { \u0026quot;description\u0026quot;: \u0026quot;This description is about a Very Important Thing and something else.\u0026quot;, \u0026quot;entity\u0026quot;: \u0026quot;Very Important Thing\u0026quot; } Search the index with the query that mentions our very important thing:\nGET test_index-2/_search { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;entity\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;prefix very important thing suffix\u0026quot;, \u0026quot;boost\u0026quot;: 2 } } } } This yields:\n{ \u0026quot;took\u0026quot; : 1, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 1.7260926, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;test_index-2\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 1.7260926, \u0026quot;_source\u0026quot; : { \u0026quot;description\u0026quot; : \u0026quot;This description is about a Very Important Thing and something else.\u0026quot;, \u0026quot;entity\u0026quot; : \u0026quot;Very Important Thing\u0026quot; } } ] } } Cool, we found what we we looking for.\nLet's try another query, this time with a mention of very important another thing:\nGET test_index-2/_search { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;entity\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;prefix very important another thing suffix\u0026quot;, \u0026quot;boost\u0026quot;: 2 } } } } This yields:\n{ \u0026quot;took\u0026quot; : 1, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 1.7260926, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;test_index-2\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 1.7260926, \u0026quot;_source\u0026quot; : { \u0026quot;description\u0026quot; : \u0026quot;This description is about a Very Important Thing and something else.\u0026quot;, \u0026quot;entity\u0026quot; : \u0026quot;Very Important Thing\u0026quot; } } ] } } Oh, the results are the same as with the previous query despite the fact that we mention Another Thing here. But it still might be OK because we matched all the terms of the entity.\nLet's try another query:\nGET test_index-2/_search { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;entity\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;prefix thing suffix\u0026quot;, \u0026quot;boost\u0026quot;: 2 } } } } This yields:\n{ \u0026quot;took\u0026quot; : 1, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 0.5753642, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;test_index-2\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 0.5753642, \u0026quot;_source\u0026quot; : { \u0026quot;description\u0026quot; : \u0026quot;This description is about a Very Important Thing and something else.\u0026quot;, \u0026quot;entity\u0026quot; : \u0026quot;Very Important Thing\u0026quot; } } ] } } Oh no, we still matched our Very Important Thing while only thing term is present in the query. But at least this time the score is lower than with previous twoqueries, 0.5753642 vs. 1.7260926. Here we clearly see the problem: we are matching short strings with long strings and partial matches raises problems.\nProposed Solution Let's leverage Synonym Graph Token Filter to solve our problem.\nPUT /test_index-1 { \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;descrition\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; }, \u0026quot;entity\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;lowercase_keyword_analyzer\u0026quot;, \u0026quot;search_analyzer\u0026quot;: \u0026quot;synonym_graph_analyzer\u0026quot; } } }, \u0026quot;settings\u0026quot;: { \u0026quot;index\u0026quot;: { \u0026quot;analysis\u0026quot;: { \u0026quot;analyzer\u0026quot;: { \u0026quot;synonym_graph_analyzer\u0026quot;: { \u0026quot;tokenizer\u0026quot;: \u0026quot;standard\u0026quot;, \u0026quot;filter\u0026quot;: [ \u0026quot;lowercase\u0026quot;, \u0026quot;my_synonym_graph\u0026quot; ] }, \u0026quot;lowercase_keyword_analyzer\u0026quot;: { \u0026quot;tokenizer\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;filter\u0026quot;: [ \u0026quot;lowercase\u0026quot; ], \u0026quot;char_filter\u0026quot;: [ \u0026quot;spaces_to_undescores_filter\u0026quot; ] } }, \u0026quot;char_filter\u0026quot;: { \u0026quot;spaces_to_undescores_filter\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;mapping\u0026quot;, \u0026quot;mappings\u0026quot;: [ \u0026quot; \\\\u0020 =\u0026gt; _\u0026quot; ] } }, \u0026quot;filter\u0026quot;: { \u0026quot;my_synonym_graph\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;synonym_graph\u0026quot;, \u0026quot;lenient\u0026quot;: true, \u0026quot;synonyms\u0026quot;: [ \u0026quot;very important thing =\u0026gt; very_important_thing\u0026quot; ] } } } } } } Let's decompose this large index configuration piece by piece:\n The entity attribute now has separate analyzers for both index and search phases. The lowercase_keyword_analyzer uses keyword tokenizer which means that tokenization will result in the sequence of token of size 1, then it normalizes tokens by lowercasing them and finally spaces_to_undescores_filter, replaces spaces to underscores. E.g. a string \u0026quot;Very Important Thing\u0026quot; is transformed into list of tokens [\u0026quot;very_important_thing\u0026quot;]. Or use out friend _analyze API:  POST test_index-1/_analyze { \u0026quot;text\u0026quot;: [\u0026quot;Very Important Thing\u0026quot;], \u0026quot;analyzer\u0026quot;: \u0026quot;lowercase_keyword_analyzer\u0026quot; } This yields:\n{ \u0026quot;tokens\u0026quot; : [ { \u0026quot;token\u0026quot; : \u0026quot;very_important_thing\u0026quot;, \u0026quot;start_offset\u0026quot; : 0, \u0026quot;end_offset\u0026quot; : 20, \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;, \u0026quot;position\u0026quot; : 0 } ] } The synonym_graph_analyzer use standard tokenizer, which is followed by the lowercase filter, and then the my_synonym_graph token filter is applied. We've set up one synonym \u0026quot;very important thing =\u0026gt; very_important_thing\u0026quot;. E.g.  POST test_index-1/_analyze { \u0026quot;text\u0026quot;: [\u0026quot;prefix very important thing suffix\u0026quot;], \u0026quot;analyzer\u0026quot;: \u0026quot;synonym_graph_analyzer\u0026quot; } This yields:\n{ \u0026quot;tokens\u0026quot; : [ { \u0026quot;token\u0026quot; : \u0026quot;prefix\u0026quot;, \u0026quot;start_offset\u0026quot; : 0, \u0026quot;end_offset\u0026quot; : 6, \u0026quot;type\u0026quot; : \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;, \u0026quot;position\u0026quot; : 0 }, { \u0026quot;token\u0026quot; : \u0026quot;very_important_thing\u0026quot;, \u0026quot;start_offset\u0026quot; : 7, \u0026quot;end_offset\u0026quot; : 27, \u0026quot;type\u0026quot; : \u0026quot;SYNONYM\u0026quot;, \u0026quot;position\u0026quot; : 1 }, { \u0026quot;token\u0026quot; : \u0026quot;suffix\u0026quot;, \u0026quot;start_offset\u0026quot; : 28, \u0026quot;end_offset\u0026quot; : 34, \u0026quot;type\u0026quot; : \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;, \u0026quot;position\u0026quot; : 2 } ] } After analysis we have 3 tokens [\u0026quot;prefix\u0026quot;, \u0026quot;very_important_thing\u0026quot;, \u0026quot;suffix\u0026quot;]. Notice \u0026quot;very_important_thing\u0026quot; token: this is equal to the right-hand-side from our synonym definitions. Now let's run queries from the previous section:\nGET test_index-1/_search { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;entity\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;prefix very important thing suffix\u0026quot;, \u0026quot;boost\u0026quot;: 2 } } } } This yields:\n{ \u0026quot;took\u0026quot; : 1, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 0.5753642, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;test_index-1\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 0.5753642, \u0026quot;_source\u0026quot; : { \u0026quot;description\u0026quot; : \u0026quot;This description is about a Very Important Thing and something else.\u0026quot;, \u0026quot;entity\u0026quot; : \u0026quot;Very Important Thing\u0026quot; } } ] } } As expected: exact match -\u0026gt; hit.\nAnother query:\nGET test_index-1/_search { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;entity\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;prefix very important another thing suffix\u0026quot;, \u0026quot;boost\u0026quot;: 2 } } } } This yields:\n{ \u0026quot;took\u0026quot; : 0, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 0, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : null, \u0026quot;hits\u0026quot; : [ ] } } No hits! Good! The document is not going to be boosted despite the fact that all tokens match.\nAnd the last one:\nGET test_index-1/_search { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;entity\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;prefix thing suffix\u0026quot;, \u0026quot;boost\u0026quot;: 2 } } } } This yields:\n{ \u0026quot;took\u0026quot; : 1, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 0, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : null, \u0026quot;hits\u0026quot; : [ ] } } No hits! Good. This means that also substring doesn't match.\nDiscussion Synonym Graph Token Filter can \u0026ldquo;replace\u0026rdquo; a sequence of tokens (e.g. a phrase) with another sequence of tokens. In this particular example: many tokens were replaced with one token.\n One field can have only one analyzer pair for index and search phases. If we want another analysis pipeline for the entity attribute we have to create another field with the analyzers specified, e.g. stemmed phrase with lower boost. The synonym list must be prepared before the index creation. Management of the synonym list might complicate index management, e.g. you use templates for your index management. The overal solution in general might look a bit too complicated.  ","date":1576972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576972800,"objectID":"bbf1ba4712ba08644677c25dbacd8b0b","permalink":"https://www.jocas.lt/blog/post/synonym-graph-phrase-search/","publishdate":"2019-12-22T00:00:00Z","relpermalink":"/blog/post/synonym-graph-phrase-search/","section":"post","summary":"An idea on how to search for short string with a long query string","tags":["elasticsearch"],"title":"Phrase Search with Synonym Graph Token Filter in Elasticsearch","type":"post"},{"authors":["Dainius Jocas"],"categories":["elasticsearch","percolator"],"content":"This time I need to percolate texts with different analyzers for index and search analyzers.\nLet's elaborate a bit on previous article and explicitly declare analyzers to use.\nDefine index:\nPUT /my-index { \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;standard\u0026quot;, \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot; }, \u0026quot;query\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;percolator\u0026quot; } } } } Then define 2 slightly different percolator queries (notice the difference between \u0026quot;bonsai tree\u0026quot; and \u0026quot;bonsai, tree\u0026quot;).\nPUT /my-index/_doc/1?refresh { \u0026quot;query\u0026quot;: { \u0026quot;match_phrase\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;bonsai tree\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;standard\u0026quot; } } } } PUT /my-index/_doc/2?refresh { \u0026quot;query\u0026quot;: { \u0026quot;match_phrase\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;bonsai, tree\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;standard\u0026quot; } } } } Let's percolate:\nGET /my-index/_search? { \u0026quot;query\u0026quot;: { \u0026quot;percolate\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;query\u0026quot;, \u0026quot;document\u0026quot;: { \u0026quot;message\u0026quot;: \u0026quot;A new bonsai tree in the office\u0026quot; } } }, \u0026quot;highlight\u0026quot;: { \u0026quot;fields\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;fvh\u0026quot; } } } } This yields:\n{ \u0026quot;took\u0026quot; : 80, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 2, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 0.26152915, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;my-index\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;2\u0026quot;, \u0026quot;_score\u0026quot; : 0.26152915, \u0026quot;_source\u0026quot; : { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;message\u0026quot; : { \u0026quot;query\u0026quot; : \u0026quot;bonsai, tree\u0026quot;, \u0026quot;analyzer\u0026quot; : \u0026quot;standard\u0026quot; } } } }, \u0026quot;fields\u0026quot; : { \u0026quot;_percolator_document_slot\u0026quot; : [ 0 ] }, \u0026quot;highlight\u0026quot; : { \u0026quot;message\u0026quot; : [ \u0026quot;A new \u0026lt;em\u0026gt;bonsai tree\u0026lt;/em\u0026gt; in the office\u0026quot; ] } }, { \u0026quot;_index\u0026quot; : \u0026quot;my-index\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 0.26152915, \u0026quot;_source\u0026quot; : { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;message\u0026quot; : { \u0026quot;query\u0026quot; : \u0026quot;bonsai tree\u0026quot;, \u0026quot;analyzer\u0026quot; : \u0026quot;standard\u0026quot; } } } }, \u0026quot;fields\u0026quot; : { \u0026quot;_percolator_document_slot\u0026quot; : [ 0 ] }, \u0026quot;highlight\u0026quot; : { \u0026quot;message\u0026quot; : [ \u0026quot;A new \u0026lt;em\u0026gt;bonsai tree\u0026lt;/em\u0026gt; in the office\u0026quot; ] } } ] } } As expected: 2 documents matched.\nBut now lets change the analyzer of the second percolation query to whitespace:\nPUT /my-index/_doc/2?refresh { \u0026quot;query\u0026quot;: { \u0026quot;match_phrase\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;bonsai, tree\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;whitespace\u0026quot; } } } } Run the percolator:\n GET /my-index/_search? { \u0026quot;query\u0026quot;: { \u0026quot;percolate\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;query\u0026quot;, \u0026quot;document\u0026quot;: { \u0026quot;message\u0026quot;: \u0026quot;A new bonsai tree in the office\u0026quot; } } }, \u0026quot;highlight\u0026quot;: { \u0026quot;fields\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;fvh\u0026quot; } } } } This yields:\n{ \u0026quot;took\u0026quot; : 5, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 0.26152915, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;my-index\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 0.26152915, \u0026quot;_source\u0026quot; : { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;message\u0026quot; : { \u0026quot;query\u0026quot; : \u0026quot;bonsai tree\u0026quot;, \u0026quot;analyzer\u0026quot; : \u0026quot;standard\u0026quot; } } } }, \u0026quot;fields\u0026quot; : { \u0026quot;_percolator_document_slot\u0026quot; : [ 0 ] }, \u0026quot;highlight\u0026quot; : { \u0026quot;message\u0026quot; : [ \u0026quot;A new \u0026lt;em\u0026gt;bonsai tree\u0026lt;/em\u0026gt; in the office\u0026quot; ] } } ] } } As expected: only 1 percolator query matched our input.\nPhrases with Stopwords Say, we have a phrase \u0026quot;bonsai is tree\u0026quot; and we percolate text A new bonsai in tree in the office with the standard analyzer for indexing and english for search analyzer. There should be no matches. Let's try:\nDELETE my-index PUT /my-index { \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;standard\u0026quot;, \u0026quot;search_analyzer\u0026quot;: \u0026quot;english\u0026quot;, \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot; }, \u0026quot;query\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;percolator\u0026quot; } } } } PUT /my-index/_doc/1?refresh { \u0026quot;query\u0026quot;: { \u0026quot;match_phrase\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;bonsai is tree\u0026quot; } } } } GET /my-index/_search? { \u0026quot;query\u0026quot;: { \u0026quot;percolate\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;query\u0026quot;, \u0026quot;document\u0026quot;: { \u0026quot;message\u0026quot;: \u0026quot;A new bonsai in tree in the office\u0026quot; } } }, \u0026quot;highlight\u0026quot;: { \u0026quot;fields\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;fvh\u0026quot; } } } } And, surprisingly, this yields:\n{ \u0026quot;took\u0026quot; : 2, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 0.26152915, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;my-index\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 0.26152915, \u0026quot;_source\u0026quot; : { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;message\u0026quot; : { \u0026quot;query\u0026quot; : \u0026quot;bonsai is tree\u0026quot; } } } }, \u0026quot;fields\u0026quot; : { \u0026quot;_percolator_document_slot\u0026quot; : [ 0 ] } } ] } } We have a match! Also notice that the highlighter is broken!\nThe problem that these two analyzers have different stopword lists (no stopwords for standard and several English stopwords for english analyzer) and the phrase contains a stopword that is not shared between analyzers.\nLet's fix this surprise with search_quote_analyzer.\nDELETE my-index PUT /my-index { \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;standard\u0026quot;, \u0026quot;search_analyzer\u0026quot;: \u0026quot;english\u0026quot;, \u0026quot;search_quote_analyzer\u0026quot;: \u0026quot;standard\u0026quot;, \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot; }, \u0026quot;query\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;percolator\u0026quot; } } } } PUT /my-index/_doc/1?refresh { \u0026quot;query\u0026quot;: { \u0026quot;match_phrase\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;bonsai is tree\u0026quot; } } } } GET /my-index/_search? { \u0026quot;query\u0026quot;: { \u0026quot;percolate\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;query\u0026quot;, \u0026quot;document\u0026quot;: { \u0026quot;message\u0026quot;: \u0026quot;A new bonsai in tree in the office\u0026quot; } } }, \u0026quot;highlight\u0026quot;: { \u0026quot;fields\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;fvh\u0026quot; } } } } This yields:\n{ \u0026quot;took\u0026quot; : 1, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 0, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : null, \u0026quot;hits\u0026quot; : [ ] } } No hits, as expected.\nLet's check if the expected behaviour is still there:\nGET /my-index/_search? { \u0026quot;query\u0026quot;: { \u0026quot;percolate\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;query\u0026quot;, \u0026quot;document\u0026quot;: { \u0026quot;message\u0026quot;: \u0026quot;A new bonsai is tree in the office\u0026quot; } } }, \u0026quot;highlight\u0026quot;: { \u0026quot;fields\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;fvh\u0026quot; } } } } This yields:\n{ \u0026quot;took\u0026quot; : 4, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 0.39229375, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;my-index\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 0.39229375, \u0026quot;_source\u0026quot; : { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;message\u0026quot; : { \u0026quot;query\u0026quot; : \u0026quot;bonsai is tree\u0026quot; } } } }, \u0026quot;fields\u0026quot; : { \u0026quot;_percolator_document_slot\u0026quot; : [ 0 ] }, \u0026quot;highlight\u0026quot; : { \u0026quot;message\u0026quot; : [ \u0026quot;A new \u0026lt;em\u0026gt;bonsai is tree\u0026lt;/em\u0026gt; in the office\u0026quot; ] } } ] } } Good. Even the highlighting works.\n","date":1576627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576627200,"objectID":"e3f59a2e678c8500ecbac9f71472142b","permalink":"https://www.jocas.lt/blog/post/percolator-phrase-analyzers/","publishdate":"2019-12-18T00:00:00Z","relpermalink":"/blog/post/percolator-phrase-analyzers/","section":"post","summary":"Example on how to use analyzers with the","tags":["elasticsearch","percolator"],"title":"Elasticsearch Percolator and Text Analyzers","type":"post"},{"authors":["Dainius Jocas"],"categories":["elasticsearch","percolator"],"content":"If you google How can you match a long query text to a short text field? it will point you to the Stack Overflow page or here where the answer is to use Elasticsearch Percolator.\nMy search items are phrases meaning that it should match all terms in order. Let's create a sample setup in Kibana (v7.5) Dev dashboard.\n Create an index for percolation:  PUT /my-index { \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot; }, \u0026quot;query\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;percolator\u0026quot; } } } } Note on \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot;: this allows Fast Vector Highlighter to highlight combined phrase not just separate qeury terms.\nStore one phrase query:  PUT /my-index/_doc/1?refresh { \u0026quot;query\u0026quot;: { \u0026quot;match_phrase\u0026quot;: { \u0026quot;message\u0026quot;: \u0026quot;bonsai tree\u0026quot; } } } Percolate a document:  GET /my-index/_search? { \u0026quot;query\u0026quot;: { \u0026quot;percolate\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;query\u0026quot;, \u0026quot;document\u0026quot;: { \u0026quot;message\u0026quot;: \u0026quot;A new bonsai tree in the office\u0026quot; } } }, \u0026quot;highlight\u0026quot;: { \u0026quot;fields\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;fvh\u0026quot; } } } } Note on \u0026quot;type\u0026quot;: \u0026quot;fvh\u0026quot;: this instructs Elasticsearch to use the Fast Vector Highlighter.\nThe query yields:\n{ \u0026quot;took\u0026quot; : 23, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 0.26152915, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;my-index\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 0.26152915, \u0026quot;_source\u0026quot; : { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;message\u0026quot; : \u0026quot;bonsai tree\u0026quot; } } }, \u0026quot;fields\u0026quot; : { \u0026quot;_percolator_document_slot\u0026quot; : [ 0 ] }, \u0026quot;highlight\u0026quot; : { \u0026quot;message\u0026quot; : [ \u0026quot;A new \u0026lt;em\u0026gt;bonsai tree\u0026lt;/em\u0026gt; in the office\u0026quot; ] } } ] } } As we see highlighter correctly marker the search phrase.\nStoring additional data with percolator queries Percolation result can be used to connect pieces of information in your system, e.g. store a subscriber_email attribute of the user that wants to be notified when the query matches along with the percolator query.\nPUT /my-index/_doc/1?refresh { \u0026quot;query\u0026quot;: { \u0026quot;match_phrase\u0026quot;: { \u0026quot;message\u0026quot;: \u0026quot;bonsai tree\u0026quot; } }, \u0026quot;subscriber_email\u0026quot;: \u0026quot;subscriber_email@example.com\u0026quot; } Then query:\nGET /my-index/_search? { \u0026quot;query\u0026quot;: { \u0026quot;percolate\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;query\u0026quot;, \u0026quot;document\u0026quot;: { \u0026quot;message\u0026quot;: \u0026quot;A new bonsai tree in the office\u0026quot; } } }, \u0026quot;highlight\u0026quot;: { \u0026quot;fields\u0026quot;: { \u0026quot;message\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;fvh\u0026quot; } } } } This query yields:\n{ \u0026quot;took\u0026quot; : 10, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 0.26152915, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;my-index\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 0.26152915, \u0026quot;_source\u0026quot; : { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;message\u0026quot; : \u0026quot;bonsai tree\u0026quot; } }, \u0026quot;subscriber_email\u0026quot; : \u0026quot;subscriber_email@example.com\u0026quot; }, \u0026quot;fields\u0026quot; : { \u0026quot;_percolator_document_slot\u0026quot; : [ 0 ] }, \u0026quot;highlight\u0026quot; : { \u0026quot;message\u0026quot; : [ \u0026quot;A new \u0026lt;em\u0026gt;bonsai tree\u0026lt;/em\u0026gt; in the office\u0026quot; ] } } ] } } Now, take the email under the \u0026quot;subscriber_email\u0026quot; from the response and send an email with the highlight.\n","date":1576627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576627200,"objectID":"8e98378fbfbaafa1f97ba3a46fd35817","permalink":"https://www.jocas.lt/blog/post/es-percolator-phrase-highlight/","publishdate":"2019-12-18T00:00:00Z","relpermalink":"/blog/post/es-percolator-phrase-highlight/","section":"post","summary":"Investigating the Elasticsearch percolator.","tags":["elasticsearch","search"],"title":"Phrase Highlighting with the Elasticsearch Percolator","type":"post"},{"authors":["Dainius Jocas"],"categories":["clojure","aws","lambda","devops"],"content":"I was writing a Clojure application and the plan was to deploy it as a AWS Lambda. The question I'm going to answer in this blog post is: how to build an uberjar for AWS Lambda with Uberdeps?\nTL;DR Add an alias to the deps.edn for uberjar building:\n{:aliases {:uberjar {:extra-deps {uberdeps {:mvn/version \u0026quot;0.1.6\u0026quot;}} :main-opts [\u0026quot;-m\u0026quot; \u0026quot;uberdeps.uberjar\u0026quot;]}}} Create an executable file compile.clj in the project root folder:\ntouch compile.clj chmod +x compile.clj Put this code in the compile.clj file:\nRun:\n(rm -rf classes \u0026amp;\u0026amp; \\ \tmkdir classes \u0026amp;\u0026amp; \\ \t./compile.clj \u0026amp;\u0026amp; \\ \tclojure -A:uberjar --target target/UBERJAR_NAME.jar) I'd advise put that last script into a Makefile ;)\n Introduction To deploy your Clojure code to AWS Lambda you need to package it as an uberjar. If your project is managed with deps.edn, basically you're on your own to find a suitable library to package your code.\nFor some time to build uberjars for deps.edn projects I was using Cambada. It did the job but I was not entirely happy with the library for a couple of reasons:\n the library seems to be no longer maintained; it has various bugs with transitive Git dependencies. I've found out that these bugs are fixed in a fork of the Cambada and I used it as a git dependency.  Because building an uberjar for deps.edn boils down to just finding a library there is always temptation to try something new.\nEnter Uberdeps For my toy project I wanted to try out Uberdeps. The introduction blog post got me interested and I really liked the main idea:\n Takes deps.edn and packs an uberjar out of it.\n Sounds like exactly what I need.\nTrouble I've written my application, added all the things needed to deploy it as an AWS Lambda, build an uberjar with Uberdeps, deployed the app with the AWS CloudFormation, but when I've invoked the Lambda I've received an error:\n{ \u0026quot;message\u0026quot; : \u0026quot;Internal server error\u0026quot; } After searching through the AWS CloudWatch logs I've found:\nClass not found: my.Lambda: java.lang.ClassNotFoundException java.lang.ClassNotFoundException: my.Lambda at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:348) The my.Lambda class was not found.\nAfter taking a look at the contents of the uberjar I've noticed that the my.Lambda class is indeed not inside the Uberjar. Ah, it seems that AOT (Ahead-of-Time) is not done out of the box. After searching and not finding a flag or some parameter that I need to pass to force the AOT compilation in the Uberdeps README, I've discovered an already closed pull request: the AOT compilation functionality is not implemented.\nI was in trouble.\nSolution The solution was to manually perform AOT compilation of the relevant namespaces right before building an uberjar and then instruct Uberdeps to put the resulting class files into the uberjar.\nTo do AOT compilation I've written a Clojure script compile.clj:\nInspiration on how to write the script was taken from here and here.\nTo instruct Uberdeps to put class files to the uberjar I've added classes directory to the :paths vector in deps.edn.\nJust for the convenience, in the Makefile I've put commands for AOT compilation right before the command to build an uberjar:\nuberjar: rm -rf classes mkdir classes ./compile.clj clojure -A:uberjar --target target/my-jar-name.jar And that is it! I have an uberjar with my.Lambda class and the AWS Lambda runtime is happy.\nDiscussion The solution is not bullet proof because:\n it assumes that the main deps.end file is called deps.edn; compiled classes are put in the classes directory; the alias for which namespaces should be AOT compiled is the default alias.  I hope that when a more generic solution will be needed either the Uberdeps will have an option for AOT compilatoin or I'll be clever enough to deal with the situation and write a follow up blog post with the workaround.\n","date":1573776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573776000,"objectID":"bc08dd6e0a5cfada2a44f4a636a8db0f","permalink":"https://www.jocas.lt/blog/post/uberdeps-for-aws-lambda/","publishdate":"2019-11-15T00:00:00Z","relpermalink":"/blog/post/uberdeps-for-aws-lambda/","section":"post","summary":"A guide on how to build an Uberjar for AWS Lambda with `tonsky/uberdeps`","tags":["clojure","devops","aws","lambda"],"title":"Using Uberdeps to Build AWS Lambda Uberjar","type":"post"},{"authors":["Dainius Jocas"],"categories":["clojure","gitlab","ci","devops"],"content":"I want to share my hard-won lessons on how to setup the Gitlab CI for Clojure projects based on tools.deps. I think that the Gitlab CI is a wonderful tool for CI workloads. But when you're going a bit sideways from the documented ways of doing things you have to do a bit of discovery for yourself.\nGitlab CI Cache Setup Usually I want to cache dependencies between all build and all branches. To achieve this I hard-code the cache key at the root of the .gitlab-ci.yml file e.g.:\ncache: key: one-key-to-rule-them-all When it comes to caching Clojure dependencies we have to be aware that there different types of dependencies. Two most common ones are: Maven and gitlibs.\nThe Gitlab CI cache works only with directories inside the project directory. While local repositories (i.e. cache) for Clojure dependencies by default are stored outside the project directory (~/.m2 and ~/.gitlibs). Therefore, we have to provide parameters for our build tool to change the default directories for storing the dependencies.\nTo specify Maven local repository we can provide :mvn/local-repo parameter e.g.:\nclojure -Sdeps \u0026#39;{:mvn/local-repo \u0026#34;./.m2/repository\u0026#34;}\u0026#39; -A:test Having configured local maven repository in our gitlab-ci.yml we can specify:\ncache: key: one-key-to-rule-them-all paths: - ./.m2/repository When it comes to gitlibs there is no public API for changing the default directory in tools.deps. But the underlying tools.gitlibs uses an environment variable to set where to store the gitlibs conveniently named GITLIBS. E.g.\n$ (export GITLIBS=\u0026#34;.gitlibs/\u0026#34; \u0026amp;\u0026amp; clojure -A:test) Of course, we should not forget to configure the cache:\ncache: key: one-key-to-rule-them-all paths: - ./.gitlibs To use caching for both types of dependencies:\n(export GITLIBS=\u0026#34;.gitlibs/\u0026#34; \u0026amp;\u0026amp; clojure -Sdeps \u0026#39;{:mvn/local-repo \u0026#34;./.m2/repository\u0026#34;}\u0026#39; -A:test) And setup the cache:\ncache: key: one-key-to-rule-them-all paths: - ./.m2/repository - ./.gitlibs If you want to disable cache for a particular job (e.g. you're linting with clj-kondo, which is delivered as a GraalVM compiled native image), just give an empty map for a job's cache setup, e.g.:\nlint: stage: test image: borkdude/clj-kondo cache: {} when: always script: - clj-kondo --lint src test I've used the Gitlab CI cache while working on a streaming-text search library Beagle. A full .gitlab-ci.yml file example of the setup can be found here.\nHope this helps!\n","date":1573430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573430400,"objectID":"10dfc9aba13fb40f8ec0be74224e4205","permalink":"https://www.jocas.lt/blog/post/gitlab-ci-clojure-dependencies/","publishdate":"2019-11-11T00:00:00Z","relpermalink":"/blog/post/gitlab-ci-clojure-dependencies/","section":"post","summary":"A guide on how to use Gitlab CI Cache for Clojure Dependencies","tags":["clojure","devops"],"title":"Using Gitlab CI Cache for Clojure Dependencies","type":"post"},{"authors":["Dainius Jocas"],"categories":null,"content":"The source code of the demo project can be found here.\n","date":1559242800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559242800,"objectID":"86663215daf06a1fb32613517d99226f","permalink":"https://www.jocas.lt/blog/talk/vilnius-clojure-meetup/","publishdate":"2019-11-11T19:00:00Z","relpermalink":"/blog/talk/vilnius-clojure-meetup/","section":"talk","summary":"Sharing Joy of Clojure Programming","tags":["meetup","clojure","lambda","aws","graalvm"],"title":"Clojure Workflow @ TokenMill","type":"talk"}]